{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the market data set \n",
    "\n",
    "# Probably a less circuitous route to getting this done, my pd skills are rusty...\n",
    "\n",
    "md = pd.read_csv('Tech_Eval/market_data.csv')\n",
    "inter = md[['base_asset_id', 'price_open']]\n",
    "mdbtc = inter[inter['base_asset_id'] == 'Bitcoin_BTC_BTC']\n",
    "mdbtc_arr = mdbtc['price_open'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two variables determining how we carve up our data. \n",
    "split = len(mdbtc_arr) - 40\n",
    "train_size = int(len(mdbtc_arr) * .50)\n",
    "\n",
    "# Arriving at a train and test set\n",
    "dataset = mdbtc_arr[:split]\n",
    "train, test = dataset[:train_size], dataset[train_size:]\n",
    "\n",
    "# Setting aside a small chunk of the data for a final evaluation. \n",
    "# holdout =  mdbtc_arr[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Predictive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13179.25688155909\n"
     ]
    }
   ],
   "source": [
    "model = AR(mdbtc_arr)\n",
    "model_fit = model.fit()\n",
    "yhat = model_fit.predict(len(mdbtc_arr), len(mdbtc_arr))\n",
    "print(yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving-averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10466.667170191871\n"
     ]
    }
   ],
   "source": [
    "model = ARMA(mdbtc_arr, order=(0, 1))\n",
    "model_fit = model.fit(disp=False)\n",
    "\n",
    "yhat = model_fit.predict(len(mdbtc_arr), len(mdbtc_arr))\n",
    "print(yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregressive Moving-averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13543.738537098749\n"
     ]
    }
   ],
   "source": [
    "model = ARMA(mdbtc_arr, order=(2, 1))\n",
    "model_fit = model.fit(disp=False)\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(mdbtc_arr), len(mdbtc_arr))\n",
    "print(yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregressive Integrated Moving-averages (with validation)\n",
    "\n",
    "All predictive analysis is predicated on making certain assumptions about the underlying data, and our success at reducing the uncertainty of the future depends in large part on how well these assumptions hold up. \n",
    "\n",
    "With time series data we are making the assumption that our data are stationary -- that is, that they do not have some underlying temporal structure which could be described by a [unit root test](https://en.wikipedia.org/wiki/Unit_root_test).\n",
    "\n",
    "Below we have code adapted from [Jason Brownlee](https://machinelearningmastery.com/time-series-forecast-case-study-python-monthly-armed-robberies-boston/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -10.701278\n"
     ]
    }
   ],
   "source": [
    "# Are we stationary? \n",
    "\n",
    "def difference(data):\n",
    "    diff = list()\n",
    "    for i in range(1, len(data)):\n",
    "        value = data[i] - data[i - 1]\n",
    "        diff.append(value)\n",
    "    return pd.Series(diff)\n",
    "\n",
    "stationary = difference(mdbtc_arr)\n",
    "stationary.index = mdbtc.index[1:]\n",
    "\n",
    "result = adfuller(stationary)\n",
    "print('ADF Statistic: %f' % result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lower ADF score means a higher likelihood that the data are stationary and our analysis will be valid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive ARIMA, just getting used to the `statsmodel` interface and getting a basic iteration up and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8537.84207485588\n"
     ]
    }
   ],
   "source": [
    "model = ARIMA(dataset, order=(1, 2, 1))\n",
    "model_fit = model.fit(disp=False)\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(mdbtc_arr), len(mdbtc_arr), typ='levels')\n",
    "print(yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More sophisticated model, with validation \n",
    "\n",
    "Jason Brownlee of [Machine Learning Mastery](https://machinelearningmastery.com/) fame notes that there are two parts to validating a time series model - performance measure and testing strategy.\n",
    "\n",
    "A performance measure is some metric by which we gauge how well our model is doing. Here I've chose to use a standard tool for the job: the root mean-squared error, or RMSE.\n",
    "\n",
    "The mean-squared error takes the average distance between predicted values and actual values, and the root mean-squared error merely takes the square root of of the mean-squared error. The advantage of taking this final step  is that the units are preserved (i.e. 'dollars' as opposed to 'dollars squared'), and the metric is therefore more easily interpretible. \n",
    "\n",
    "Validating a time series model can be a little tricky. Here, I've divided the data into a 'train' set and a 'test' set, each comprising 50% of the total data, and elected to use a 'walk forward' test strategy. \n",
    "\n",
    "In essence, the model takes the entire training set and makes a single prediction with it, which it compares to the first actual data point in the test set. Then this data point is added to the training set -- which therefore grows in size by one data point -- and makes another single prediction, which is compared to the next data point in the test set. \n",
    "\n",
    "At each step in this walking process the difference between the predicted and actual values is noted and, when the process is finished, a final RMSE is calculated telling us how far off our predictions tended to be, on average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Predicted = 8163.322, Expected = 7838.611\n",
      ">Predicted = 7231.575, Expected = 6674.394\n",
      ">Predicted = 6629.826, Expected = 6532.896\n",
      ">Predicted = 6024.098, Expected = 5985.887\n",
      ">Predicted = 6334.930, Expected = 6404.785\n",
      ">Predicted = 7613.237, Expected = 7555.662\n",
      ">Predicted = 7008.918, Expected = 7238.580\n",
      ">Predicted = 8172.398, Expected = 7960.392\n",
      ">Predicted = 9102.172, Expected = 9232.296\n",
      ">Predicted = 9244.526, Expected = 8774.818\n",
      ">Predicted = 7955.099, Expected = 7682.265\n",
      ">Predicted = 6882.474, Expected = 6815.312\n",
      ">Predicted = 6933.993, Expected = 7773.527\n",
      ">Predicted = 8488.701, Expected = 8046.967\n",
      ">Predicted = 9056.909, Expected = 9117.040\n",
      ">Predicted = 10375.357, Expected = 10115.465\n",
      ">Predicted = 10912.562, Expected = 10006.713\n",
      "RMSE: 355.370\n"
     ]
    }
   ],
   "source": [
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "\n",
    "# walk-forward validation \n",
    "for i in range(len(test)):\n",
    "    model = ARIMA(history, order=(1,2,1))\n",
    "    model_fit = model.fit(disp=0)\n",
    "    yhat = model_fit.forecast()[0]\n",
    "    predictions.append(yhat)\n",
    "    obs = test[i]\n",
    "    history.append(obs)\n",
    "    if i % 10 == 0: # so as to not print out literally every iteration.\n",
    "        print('>Predicted = %.3f, Expected = %.3f' % (yhat, obs))\n",
    "\n",
    "# report performance\n",
    "mse = mean_squared_error(test, predictions)\n",
    "rmse = sqrt(mse)\n",
    "print('RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm uncertain of the best way to interpret this RMSE, but given that the standard deviation for this data set is approximately [1] 2527.235:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>415.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6993.243803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2527.232533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3237.278203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6110.909430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6566.161727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8196.596443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16781.302024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         price_open\n",
       "count    415.000000\n",
       "mean    6993.243803\n",
       "std     2527.232533\n",
       "min     3237.278203\n",
       "25%     6110.909430\n",
       "50%     6566.161727\n",
       "75%     8196.596443\n",
       "max    16781.302024"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdbtc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " our model isn't doing too badly.\n",
    " \n",
    "[1] - It might be a little more or a little less, because the std was calculated on the full `price_open` values for the market data, while the model worked on `train` and `test` data which were subsets of these market data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Autoregressive Integrated moving-average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(mdbtc_arr, order=(1, 1, 1), seasonal_order=(1, 1, 1, 1))\n",
    "model_fit = model.fit(disp=False)\n",
    "# make prediction\n",
    "yhat = model_fit.predict(len(mdbtc_arr), len(mdbtc_arr))\n",
    "print(yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Predictive Model\n",
    "\n",
    "[Machine Learning Mastery](https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "        Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[0]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "yhat = series_to_supervised(list(mdbtc_arr))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Univariate predictive models (from Machine Learning Mastery)](https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/)  \n",
    "[Building and Optimizing ARIMA models for time-series predictions](https://machinelearningmastery.com/time-series-forecast-case-study-python-monthly-armed-robberies-boston/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[LSTM predictions](https://lilianweng.github.io/lil-log/2017/07/08/predict-stock-prices-using-RNN-part-1.html)   \n",
    "[Code for LSTM predictions](https://github.com/lilianweng/stock-rnn)  \n",
    "\n",
    "[Doing the same with TF and GCP](https://medium.com/google-cloud/how-to-do-time-series-prediction-using-rnns-and-tensorflow-and-cloud-ml-engine-2ad2eeb189e8)  \n",
    "\n",
    "[Echo State Networks](https://towardsdatascience.com/predicting-stock-prices-with-echo-state-networks-f910809d23d4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
